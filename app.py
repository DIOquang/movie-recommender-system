import streamlit as st
import pandas as pd
import requests
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel
import datetime

# ======================================================
# 1. C·∫§U H√åNH & API
# ======================================================
TMDB_API_KEY = "973eac1c6ee5c0af02fd6281ff2bb30b" # Key c·ªßa b·∫°n

st.set_page_config(page_title="H·ªá th·ªëng G·ª£i √Ω Phim", layout="wide")

# Kh·ªüi t·∫°o Session State ƒë·ªÉ l∆∞u l·ªãch s·ª≠ (B·ªô nh·ªõ t·∫°m th·ªùi)
if 'history' not in st.session_state:
    st.session_state['history'] = []

def fetch_poster(movie_id):
    try:
        url = f"https://api.themoviedb.org/3/movie/{movie_id}?api_key={TMDB_API_KEY}&language=en-US"
        data = requests.get(url).json()
        poster_path = data['poster_path']
        return "https://image.tmdb.org/t/p/w500/" + poster_path
    except:
        return "https://via.placeholder.com/500x750?text=No+Image"

# ======================================================
# 2. X·ª¨ L√ù D·ªÆ LI·ªÜU & AI
# ======================================================
@st.cache_data
def load_data_and_model():
    df = pd.read_csv('movies_clean.csv')
    # T·∫°o soup vector
    df['soup'] = df['overview'] + ' ' + df['genres'] + ' ' + df['keywords']
    tfidf = TfidfVectorizer(stop_words='english')
    tfidf_matrix = tfidf.fit_transform(df['soup'].fillna(''))
    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)
    return df, cosine_sim

with st.spinner('ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng AI...'):
    df, cosine_sim = load_data_and_model()

# ======================================================
# 3. SIDEBAR - L·ªäCH S·ª¨ NG∆Ø·ªúI D√ôNG (T√≠nh nƒÉng N√¢ng Cao)
# ======================================================
st.sidebar.title("üë§ H·ªì s∆° ng∆∞·ªùi d√πng")
st.sidebar.markdown("---")
st.sidebar.subheader("üïí L·ªãch s·ª≠ t√¨m ki·∫øm")

# Hi·ªÉn th·ªã l·ªãch s·ª≠ t·ª´ m·ªõi nh·∫•t ƒë·∫øn c≈© nh·∫•t
if len(st.session_state['history']) > 0:
    for item in reversed(st.session_state['history']):
        st.sidebar.text(f"‚Ä¢ {item}")
    
    if st.sidebar.button("X√≥a l·ªãch s·ª≠"):
        st.session_state['history'] = []
        st.rerun() # Load l·∫°i trang
else:
    st.sidebar.info("Ch∆∞a c√≥ ho·∫°t ƒë·ªông n√†o.")

# ======================================================
# 4. GIAO DI·ªÜN CH√çNH
# ======================================================
st.title("üé¨ Movie Recommender System")
st.markdown("### ƒê·ªì √°n Final Project - AI Engineer")

# Tabs: Chia giao di·ªán th√†nh 2 ph·∫ßn
tab1, tab2 = st.tabs(["üîç G·ª£i √Ω Phim", "üìä Ph√¢n t√≠ch d·ªØ li·ªáu"])

with tab1:
    movie_list = df['original_title'].values
    selected_movie = st.selectbox("B·∫°n th√≠ch phim n√†o?", movie_list)

    if st.button('üöÄ G·ª£i √Ω cho t√¥i'):
        # 1. L∆∞u v√†o l·ªãch s·ª≠
        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
        log_entry = f"{selected_movie} ({timestamp})"
        st.session_state['history'].append(log_entry)
        
        # 2. X·ª≠ l√Ω g·ª£i √Ω
        st.write(f"Nh·ªØng b·ªô phim t∆∞∆°ng t·ª± v·ªõi **{selected_movie}**:")
        
        # Logic g·ª£i √Ω (nh∆∞ c≈©)
        indices = pd.Series(df.index, index=df['original_title']).drop_duplicates()
        if selected_movie in indices:
            idx = indices[selected_movie]
            sim_scores = list(enumerate(cosine_sim[idx]))
            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
            sim_scores = sim_scores[1:6]
            
            cols = st.columns(5)
            for i, col in enumerate(cols):
                movie_idx = sim_scores[i][0]
                title = df.iloc[movie_idx].original_title
                movie_id = df.iloc[movie_idx].id
                poster = fetch_poster(movie_id)
                
                with col:
                    st.image(poster)
                    st.caption(title)
        else:
            st.error("Kh√¥ng t√¨m th·∫•y phim n√†y trong d·ªØ li·ªáu!")

with tab2:
    st.header("üìä Ph√¢n t√≠ch d·ªØ li·ªáu (EDA)")
    st.write("Th·ªëng k√™ t·ªïng quan v·ªÅ b·ªô d·ªØ li·ªáu phim TMDB 5000:")
    
    # Hi·ªÉn th·ªã s·ªë li·ªáu t·ªïng quan (KPIs)
    col1, col2, col3 = st.columns(3)
    col1.metric("T·ªïng s·ªë phim", df.shape[0])
    col2.metric("S·ªë l∆∞·ª£ng t·ª´ kh√≥a", df['keywords'].nunique()) # V√≠ d·ª• minh h·ªça
    col3.metric("ƒêi·ªÉm ƒë√°nh gi√° TB", round(df['vote_average'].mean(), 2))
    
    st.markdown("---")

    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì 1 v√† 2 song song
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("Top Th·ªÉ lo·∫°i ph·ªï bi·∫øn")
        try:
            st.image("chart_top_genres.png", use_container_width=True)
        except:
            st.error("Ch∆∞a th·∫•y file ·∫£nh. H√£y ch·∫°y l·∫°i step2_cleaning_eda.py")
            
    with c2:
        st.subheader("Ph√¢n b·ªë ƒëi·ªÉm ƒë√°nh gi√°")
        try:
            st.image("chart_rating_distribution.png", use_container_width=True)
        except:
            st.error("Ch∆∞a th·∫•y file ·∫£nh.")

    st.markdown("---")
    
    # Hi·ªÉn th·ªã WordCloud l·ªõn ·ªü d∆∞·ªõi
    st.subheader("‚òÅÔ∏è WordCloud: C√°c t·ª´ kh√≥a n·ªïi b·∫≠t")
    try:
        st.image("chart_wordcloud.png", use_container_width=True)
    except:
        st.write("Ch∆∞a c√≥ ·∫£nh WordCloud")